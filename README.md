<table>
  <tr>
    <td>
      <img src="https://github.com/jorditorresBCN/HPC4AIbook/blob/main/HPC4AIbook-cover.jpg" alt="Cover" width="620"/>
    </td>
    <td style="vertical-align: top; padding-left: 20px;">
      <strong>Supercomputing for Artificial Intelligence: Foundations, Architectures, and Scaling Deep Learning</strong><br>
      <strong>Author:</strong> Jordi Torres<br>
      <strong>ISBN:</strong> 979-831932835-9<br>
      <strong>Series:</strong> WATCH THIS SPACE Book Series – Barcelona<br>
      <strong>Publisher:</strong> Amazon KDP, 2025<br><br>
      Welcome to the official GitHub repository for the book <strong>HPC4AIbook</strong>.<br><br>
      This book is designed as a practical and accessible guide to <em>High Performance Computing for Artificial Intelligence </em>, covering the foundations of supercomputing, the tools and architectures required, and how to scale deep learning workloads efficiently.<br><br>
      This repository provides access to the companion materials referenced throughout the book.
    </td>
  </tr>
</table>


[**See What's Inside**](https://torres.ai/wp-content/uploads/2025/08/Book-HPC4AI.content.pdf) – [**Order Now**](https://www.amazon.com/Supercomputing-Artificial-Intelligence-Foundations-Architectures/dp/B0F4YMMS7H)


## AVAILABLE CODE: Table of Contents

### PART I — THE INFRASTRUCTURE LAYER  
1. Supercomputing Basics  
2. Supercomputing Building Blocks] 
3. [Supercomputing Software Environment and Tools](./Chapter.03)

### PART II — THE PARALLEL EXECUTION LAYER  
4. [Launching and Structuring Parallel Programs with MPI](./Chapter.04)  
5. [GPU Programming and CUDA](./Chapter.05)  
6. [Distributed GPU Programming](./Chapter.06)

### PART III — THE INTELLIGENCE ABSTRACTION LAYER  
7. [Neural Networks: Concepts and First Steps](./Chapter.07)  
8. [Training Neural Networks: Basics, CNNs, and Deployment](./Chapter.07)  
9. Getting Started with PyTorch

### PART IV — THE SCALABILITY LAYER  
10. [Introduction to Parallel Training of Neural Networks](./Chapter.10)  
11. [Practical Guide to Efficient Training with PyTorch](./Chapter.11.12)  
12. [Parallelizing Model Training with Distributed Data Parallel](./Chapter.11.12)

### PART V — THE LANGUAGE ABSTRACTION LAYER  
13. Introduction to Large Language Models 
14. [End-to-End Large Language Models Workflow](./Chapter.14)  
15. [Exploring Optimization and Scaling of LLMs](./Chapter.15)

> Additional materials will be made available as the book evolves.

---

## How to cite this book

Please use the following reference format when citing this book in academic or teaching materials:

**Torres, J. (2025).** *Supercomputing for Artificial Intelligence: Foundations, Architectures, and Scaling Deep Learning*. *WATCH THIS SPACE Book Series – Barcelona*. Amazon KDP. ISBN: 979-831932835-9.

### BibTeX entry

```bibtex
@book{HPC4AI2025,
  author    = {Jordi Torres},
  title     = {Supercomputing for Artificial Intelligence: Foundations, Architectures, and Scaling Deep Learning},
  year      = {2025},
  publisher = {Amazon KDP},
  series    = {WATCH THIS SPACE Book Series – Barcelona},
  isbn      = {979-831932835-9},
}
